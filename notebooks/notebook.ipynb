{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e61ef2d8-f315-4f7f-b07e-1de0f4e8441a",
    "_uuid": "1677fddbb95f7545b6540e9201f3339a0fdbfc5d"
   },
   "source": [
    "# Intro\n",
    "Hello! This rather quick and dirty kernel shows how to get started on segmenting nuclei using a neural network in Keras. \n",
    "\n",
    "The architecture used is the so-called [U-Net](https://arxiv.org/abs/1505.04597), which is very common for image segmentation problems such as this. I believe they also have a tendency to work quite well even on small datasets.\n",
    "\n",
    "Let's get started importing everything we need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "c332549b-8d23-4bb5-8497-e7a8eb8b21d2",
    "_uuid": "5c38504af3a84bee68c66d3cde74443c58df422f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH = '../input/stage1_train/'\n",
    "TEST_PATH = '../input/stage1_test/'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "ffa0caf0-2d1b-40f2-865b-8e6db88526b6",
    "_uuid": "3fb9d6530fbbd0e22e41fc4fd9fd9fc0bff027ac"
   },
   "outputs": [],
   "source": [
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "59c4a25d-645f-4b74-9c53-145ac78cc481",
    "_uuid": "875af74f980236825de3a650825b46e25632422c"
   },
   "source": [
    "# Get the data\n",
    "Let's first import all the images and associated masks. I downsample both the training and test images to keep things light and manageable, but we need to keep a record of the original sizes of the test images to upsample our predicted masks and create correct run-length encodings later on. There are definitely better ways to handle this, but it works fine for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "ca0cc34b-c26f-41ee-88d7-975aebdb634e",
    "_uuid": "9e389ba8bdb5b6fc03b231b6a6c84a8bde634053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing train images and masks ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 670/670 [01:56<00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing test images ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 65/65 [00:00<00:00, 66.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get and resize train images and masks\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask\n",
    "\n",
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c0523b03-1fc5-4505-a1b8-eb35ee617c8a",
    "_uuid": "d4f8327802a1ec6139ce0585953986272ba62ce1"
   },
   "source": [
    "Let's see if things look all right by drawing some random images and their associated masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "88829b53-50ce-45d9-9540-77dd7384ad4c",
    "_uuid": "283af26f0860b7069bdfd133c746e5d20971542c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucas/anaconda/envs/nuclei-detection/lib/python3.6/site-packages/matplotlib/axes/_base.py:1400: MatplotlibDeprecationWarning: The 'box-forced' keyword argument is deprecated since 2.2.\n",
      "  \" since 2.2.\", cbook.mplDeprecation)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 1)\n",
      "(128, 128)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASEAAAEYCAYAAAATaEB+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAEU5JREFUeJzt3X2MZXV9x/H3p6xoxRhAHrLu0gLJxoeaWmBjQf2DiKZAjdBEE4yJG0uyaWIrPiQK9Q/T/2pqfEos7UZU2hDUIi0b0mrJSmP/ceuMtgisyFZaWFlZjIqNJo3Ub/+4Z8I4zOzM3Kffufe+X8nkzj1z7tzvnHvvZ77nd55SVUhSK7/WugBJi80QktSUISSpKUNIUlOGkKSmDCFJTRlCkpqaWAgluTLJQ0mOJrlxUs8jabZlEjsrJjkF+C7wBuAY8A3grVX14NifTNJM2zGh3/sq4GhVfQ8gyeeBa4B1QyjJQuy2fckllwz92OXl5TFWIk3FD6vq7M1mmlQI7QIeW3X/GPC7q2dIsh/YP6Hn76WlpaWhH5tkjJVIU/HfW5lpUiG03ifmV7qdqjoAHIDF6YRGsbLabBhp3kxqYPoYcN6q+7uBxyf0XJJm2KRC6BvAniQXJDkVuA44OKHnWihVhWc+0DyZyOpYVT2d5I+BrwCnAJ+pqgcm8VySZttENtFvu4gFGxMaxzJ3bEgzYLmq9m42k3tMS2rKEJLUlCEkqSlDqAHHc6RnGEKSmprUHtMTt9EWplnpMtbWudUtZrPy90lbNZMhdLIP7Kwe3jBr9Urj4uqYpKbmNoQ8vEGaDXMbQpJmw9yHkB2R1G9zH0KS+s0Q0tyzG+43Q0hSUzO5n5C0FWu7n7X33TerH+yEJDU1k51QkrGv46/3+/xPOZu2+t6Y1t71s36I0aTZCUlqaiY7IWmcqmrsXYlb47bOTkhSUzPbCW31VBiud0v9ZickqamZ7YTWGrXjsWOaHyuvpSeKmw12QpKamptOSFpr2FPojsKtYttnJySpKTshLQzHfvrJTkhSU3ZCC8R9qSavxTjUrBu6E0pyXpJ7kxxJ8kCSG7rpZya5J8nD3e0Z4ytX0rwZZXXsaeB9VfUy4FLgnUleDtwIHKqqPcCh7r4a2uzMgp55cHKSbPi1YmX5L+rrMHQIVdXxqvpm9/3/AEeAXcA1wK3dbLcC145apDSPNgqdRQujsYwJJTkfuAg4DJxbVcdhEFRJztngMfuB/eN4fkmza+QQSvIC4EvAu6vqp1sd5KyqA8CB7ncsTuz32KxeQluzbaRN9EmewyCAbquqO7vJTyTZ2f18J3BitBIlzbNRto4FuAU4UlUfXfWjg8C+7vt9wF3Dl6dxWDsQKvVJhh0AS/Ja4F+BbwO/7Cb/KYNxoS8CvwE8Crylqn60ye9ydWwKPKq8XzZ7PebgdViuqr2bzTR0CI2TITQdhpCmbEsh5GEbkprysI0FstHJvux81JKdkKSm7IQWkJ2P+sROSFJThpCkpgwhSU0ZQpKaMoQkNWUISWrKEJLUlCEkqSlDSFJThpCkpgwhSU0ZQpKa8gDWxrwqqhadnZCkpuyEGtnsVKtefkeLwk5IUlO97oTmbbxkmIsK2BFp3tkJSWpqJkOoD5cpkjQeMxlCkuZHL8eEttLpOFYizQc7IUlN9bITmqaTdV196rLs/DSv7IQkNbWwnZDjTjqZzd4fvifGx05IUlMjh1CSU5J8K8nd3f0LkhxO8nCSLyQ5dfQypcmqql/52ur8Gt04OqEbgCOr7n8Y+FhV7QF+DFw/hueQNKdGCqEku4HfBz7d3Q/wOuCObpZbgWuH+L1zuc49r3/XIrMjGt2ondDHgfcDv+zuvwj4SVU93d0/Buxa74FJ9idZSrI0Yg2SZtjQIZTkjcCJqlpePXmdWdf9N1FVB6pqb1XtPclzbNg5zHJXsVL7yepfPc9W5ldbdkTDG2UT/WuANyW5Gnge8EIGndHpSXZ03dBu4PHRy5Q0r4buhKrqpqraXVXnA9cBX62qtwH3Am/uZtsH3DVqkfPcEdjxzBc7ou2bxH5CHwDem+QogzGiWybwHJLmRPqQ2kmmXsRW/m47ksUx7s+B7x0Alk825rvCPaYlNbWwIeTYi9QPC3sA6wqDSPDM+6APwxOLZmE7IUn9sPCdkLTaqB2RnfX22QlJasoQktbhhovpMYQkNeWYkHQSdkOTZyckqSlDSFJThpCkpgwhSU0ZQpKaMoQkNWUISWrKEJLUlCEkqSlDSFJThpCkpgwhSU0ZQpKaMoQkNWUISWrK8wlp0/Mpe04dTZKdkKSmDCFtqqq8HpcmxhCS1JQhJKmpkUIoyelJ7kjynSRHklyW5Mwk9yR5uLs9Y1zFqi1XyzQJo3ZCnwC+XFUvBV4JHAFuBA5V1R7gUHdfktaVES53+0LgP4ALa9UvSfIQcHlVHU+yE/iXqnrJJr/Lf68Nbfc94CZ7bdFyVe3dbKZROqELgSeBzyb5VpJPJzkNOLeqjgN0t+es9+Ak+5MsJVkaoQZJM26UENoBXAzcXFUXAT9jG6teVXWgqvZuJSklza9RQugYcKyqDnf372AQSk90q2F0tydGK1HSPBs6hKrqB8BjSVbGe64AHgQOAvu6afuAu0aqUBOXxHEeNTPqsWN/AtyW5FTge8A7GATbF5NcDzwKvGXE55A0x4beOjbWItw61ksbvTfsmrRFE986Jkkj81Qe2pAdj6bBTkhSU4aQpKYMIUlNGUKSmjKEJDVlCElqyhCS1JQhJKkpQ0hSU4aQpKYMIUlNGUKSmjKEJDVlCElqyhCS1JQhJKkpQ0hSU4aQpKYMIUlNGUKSmjKEJDVlCElqyhCS1JQhJKkpQ0hSU4aQpKYMIUlNjRRCSd6T5IEk9ye5PcnzklyQ5HCSh5N8Icmp4ypW0vwZOoSS7ALeBeytqlcApwDXAR8GPlZVe4AfA9ePo1BJ82nU1bEdwK8n2QE8HzgOvA64o/v5rcC1Iz6HpDk2dAhV1feBjwCPMgifp4Bl4CdV9XQ32zFg16hFSppfo6yOnQFcA1wAvBg4DbhqnVlrg8fvT7KUZGnYGiTNvh0jPPb1wCNV9SRAkjuBVwOnJ9nRdUO7gcfXe3BVHQAOdI9dN6gkzb9RxoQeBS5N8vwkAa4AHgTuBd7czbMPuGu0EiXNs1HGhA4zGID+JvDt7ncdAD4AvDfJUeBFwC1jqFPSnEpV+zUhV8ekubRcVXs3m8k9piU1ZQhJasoQktSUISSpKUNIUlOj7KwozY21W4kHu75pGuyEJDVlCEnrqKpndUeaDENIUlOGkKSmDCFJTbl1TMKtYS3ZCUlqyk5I0obW20I47q7RTkhSU4aQpG0Z9z5UhpCkphwTkvQsW+l0VuYZdYzITkhSU3ZC0hgs8lH4o3ZEdkKSmjKEpAmY9aPwk0ytmzOEJDVlCElqyoFpaQzmdSB65e+a5KqlnZCkpuyEJG1qdac3rp0UV9gJSWrKTkjStngqD0lzZdMQSvKZJCeS3L9q2plJ7knycHd7Rjc9ST6Z5GiS+5JcPMniF8HKTm9rv6R5sZVO6HPAlWum3Qgcqqo9wKHuPsBVwJ7uaz9w83jKlDSvNg2hqvoa8KM1k68Bbu2+vxW4dtX0v6mBrwOnJ9k5rmIXyWYdT986oo06tr7Vqf4Zdkzo3Ko6DtDdntNN3wU8tmq+Y920Z0myP8lSkqUha5A0B8a9dWy9YfN1/w1W1QHgAEAS/1UOadz7bAz7/Nudb173MNb2DdsJPbGymtXdnuimHwPOWzXfbuDx4cuTNO+GDaGDwL7u+33AXaumv73bSnYp8NTKapvmj2M9GodNV8eS3A5cDpyV5BjwIeDPgS8muR54FHhLN/s/AlcDR4GfA++YQM2S5kj68N/MMaFn2+7r0mKMZZT3jmNCC2G5qvZuNpN7TEtqymPHemoa53FpwQ5Ia9kJSWrKEJpx0zwh+XrPLY3KEJLUlGNCPdf3saGt1mfXNB1bfZ/06fWwE5LUlJ3QjOjTf67V7IA0KjshSU3ZCWloWxl/aH2U/6LY7phhn14XOyFNhSc300YMIUlNGUIa2jCtvB2R1jKEJDVlCGkkLQ8b0TNm+XUwhCQ15SZ6jYWHb2hYdkKSmuplJ9SnHam0Pb5mbc1iR2onJKmpXoTQJZdcsu4lg72UsDScla1lG331SS9CSNLimqkQsiOS5s9MhZCk+WMISWrKEJLUlCEkqSlDSFJThpCkpjYNoSSfSXIiyf2rpv1Fku8kuS/J3yc5fdXPbkpyNMlDSX5vUoVLmg9b6YQ+B1y5Zto9wCuq6reB7wI3ASR5OXAd8FvdY/4yySnjKraPe3tKGs2mIVRVXwN+tGbaP1fV093drwO7u++vAT5fVf9bVY8AR4FXjbFeSXNmHGNCfwj8U/f9LuCxVT871k17liT7kywlWXryySdP+gR2QNL8GimEknwQeBq4bWXSOrOte5xFVR2oqr1Vtffss88epQxJM2zo8wkl2Qe8Ebiinjmg6xhw3qrZdgOPb/a7lpeX7XSkhtYekznNz+NQnVCSK4EPAG+qqp+v+tFB4Lokz01yAbAH+LfRy5Q0TdM8WHzTTijJ7cDlwFlJjgEfYrA17LnAPV1ifr2q/qiqHkjyReBBBqtp76yq/5tU8ZJmX/pwaowk7YuQFthGOTDiatlyVe3dbCb3mJbUVC9PdC9pulpuGLITktSUISSpKUNIUlOOCUk9M0sXLhwHOyFJTdkJST2x1X32Wh5iMQl2QpKa6ksn9EPgZ91tH51FP2uzru3ra21nJeljXTD8MvvNrczUi8M2AJIsbWUX7xb6Wpt1bV9fa+trXTD52lwdk9SUISSpqT6F0IHWBZxEX2uzru3ra219rQsmXFtvxoQkLaY+dUKSFpAhJKmpXoRQkiu7K7YeTXJjwzrOS3JvkiNJHkhyQzf9zCT3JHm4uz2jUX2nJPlWkru7+xckOdzV9YUkpzaq6/Qkd3RX5T2S5LI+LLMk7+lex/uT3J7kea2W2QZXMl53GWXgk93n4b4kF0+5rqleYbl5CHVXaP0UcBXwcuCt3ZVcW3gaeF9VvQy4FHhnV8uNwKGq2gMc6u63cANwZNX9DwMf6+r6MXB9k6rgE8CXq+qlwCsZ1Nh0mSXZBbwL2FtVrwBOYXB14FbL7HM8+0rGGy2jqxhcJGIPsB+4ecp1TfcKyytn1W/1BVwGfGXV/ZuAm1rX1dVyF/AG4CFgZzdtJ/BQg1p2M3ijvg64m8E13n4I7FhvOU6xrhcCj9Bt5Fg1veky45kLcZ7J4MiAu4Hfa7nMgPOB+zdbRsBfA29db75p1LXmZ38A3NZ9/yufTeArwGWjPn/zTohtXLV1mpKcD1wEHAbOrarjAN3tOQ1K+jjwfuCX3f0XAT+pZy7H3Wq5XQg8CXy2W1X8dJLTaLzMqur7wEeAR4HjwFPAMv1YZis2WkZ9+kwMdYXl7ehDCG35qq3TkuQFwJeAd1fVT1vW0tXzRuBEVS2vnrzOrC2W2w7gYuDmqrqIwTGAzcb1VnTjK9cAFwAvBk5jsJqzVh/3UenFazvKFZa3ow8hNNRVWyclyXMYBNBtVXVnN/mJJDu7n+8ETky5rNcAb0ryX8DnGaySfRw4PcnKQcitltsx4FhVHe7u38EglFovs9cDj1TVk1X1C+BO4NX0Y5mt2GgZNf9MrLrC8tuqW/eaVF19CKFvAHu6rRanMhj4OtiikAxOzHILcKSqPrrqRweBfd33+xiMFU1NVd1UVbur6nwGy+erVfU24F7gza3q6mr7AfBYkpd0k65gcPHLpsuMwWrYpUme372uK3U1X2arbLSMDgJv77aSXQo8tbLaNg2Z9hWWpzUot8nA2NUMRuH/E/hgwzpey6C9vA/49+7ragbjL4eAh7vbMxvWeDlwd/f9hd2b4Cjwd8BzG9X0O8BSt9z+ATijD8sM+DPgO8D9wN8yuGpwk2UG3M5gbOoXDDqK6zdaRgxWez7VfR6+zWAL3zTrOspg7GflM/BXq+b/YFfXQ8BV46jBwzYkNdWH1TFJC8wQktSUISSpKUNIUlOGkKSmDCFJTRlCkpr6f1DM3xb2iH0KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if training data looks all right\n",
    "ix = random.randint(0, len(train_ids))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "print(Y_train[ix].shape)\n",
    "print(np.squeeze(Y_train[ix]).shape)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2574ffe9-b911-4bfd-a00f-9ba5c25f45de",
    "_uuid": "938648da705689a0f940ff462477c801db3f0737"
   },
   "source": [
    "Seems good!\n",
    "\n",
    "# Create our Keras metric\n",
    "\n",
    "Now we try to define the *mean average precision at different intersection over union (IoU) thresholds* metric in Keras. TensorFlow has a mean IoU metric, but it doesn't have any native support for the mean over multiple thresholds, so I tried to implement this. **I'm by no means certain that this implementation is correct, though!** Any assistance in verifying this would be most welcome! \n",
    "\n",
    "*Update: This implementation is most definitely not correct due to the very large discrepancy between the results reported here and the LB results. It also seems to just increase over time no matter what when you train ... *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "c1df6f3a-d58f-434b-9216-ef7be38637d4",
    "_uuid": "5abd38950ae99b60f8afec7656eb654a48d449fe"
   },
   "outputs": [],
   "source": [
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred):\n",
    "   pred = np.squeeze(y_pred)\n",
    "   val = np.squeeze(y_true)\n",
    "   #treshold\n",
    "   t = 0.2\n",
    "   iou = []\n",
    "   #intersection/union\n",
    "   func = np.vectorize((lambda x: True if x > t else False));\n",
    "   pred_ = func(pred)        \n",
    "   return np.sum(np.minimum(val,pred_))/np.sum(np.maximum(val,pred_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c3b9f148-1dba-4b6a-981b-6cdbf394fc3c",
    "_uuid": "986488a4c5223576be370e224426a30431911eb2"
   },
   "source": [
    "# Build and train our neural network\n",
    "Next we build our U-Net model, loosely based on [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/pdf/1505.04597.pdf) and very similar to [this repo](https://github.com/jocicmarko/ultrasound-nerve-segmentation) from the Kaggle Ultrasound Nerve Segmentation competition.\n",
    "\n",
    "![](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "c1dbc57c-b497-4ccb-b077-2053203ab7ed",
    "_uuid": "0aa97d66c29f45dfac9b0f45fcf74ba0e778ba5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128, 128, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 16) 448         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 128, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 16) 2320        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 16)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64, 64, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 32)   9248        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 64)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 64)   36928       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 128)  73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 128)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 128)  147584      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 128)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 256)    295168      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 8, 8, 256)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 256)    590080      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 128)  131200      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 128)  295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16, 16, 128)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 128)  147584      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 64)   32832       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 128)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 64)   73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 64)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 64)   36928       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 64, 32)   8224        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 64)   0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 32)   18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64, 64, 32)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 32)   9248        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 128, 128, 16) 2064        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, 128, 32) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 16) 4624        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 128, 128, 16) 0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 16) 2320        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 1)  17          conv2d_18[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,941,105\n",
      "Trainable params: 1,941,105\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build U-Net model\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss=dice_coef_loss)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "72330944-6ce7-4070-b276-c3c4b20c4fe5",
    "_uuid": "92350b6e18cc50f3fa7b6e9a02d39fcbff8238f7"
   },
   "source": [
    "*Update: Changed to ELU units, added dropout.*\n",
    "\n",
    "Next we fit the model on the training data, using a validation split of 0.1. We use a small batch size because we have so little data. I recommend using checkpointing and early stopping when training your model. I won't do it here to make things a bit more reproducible (although it's very likely that your results will be different anyway). I'll just train for 10 epochs, which takes around 10 minutes in the Kaggle kernel with the current parameters. \n",
    "\n",
    "*Update: Added early stopping and checkpointing and increased to 30 epochs.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "9415b1c4-aa69-41b9-a1e3-d6053dbd4f64",
    "_uuid": "c060db22daa2abf12b28240cd81bbcbf1ce1bf87",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 603 samples, validate on 67 samples\n",
      "Epoch 1/50\n",
      "603/603 [==============================] - 188s 312ms/step - loss: -0.4710 - val_loss: -0.5607\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -0.56069, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 2/50\n",
      "603/603 [==============================] - 190s 315ms/step - loss: -0.5886 - val_loss: -0.6015\n",
      "\n",
      "Epoch 00002: val_loss improved from -0.56069 to -0.60153, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 3/50\n",
      "603/603 [==============================] - 192s 318ms/step - loss: -0.6209 - val_loss: -0.6089\n",
      "\n",
      "Epoch 00003: val_loss improved from -0.60153 to -0.60890, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 4/50\n",
      "603/603 [==============================] - 189s 314ms/step - loss: -0.6234 - val_loss: -0.6262\n",
      "\n",
      "Epoch 00004: val_loss improved from -0.60890 to -0.62616, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 5/50\n",
      "603/603 [==============================] - 189s 313ms/step - loss: -0.6335 - val_loss: -0.6303\n",
      "\n",
      "Epoch 00005: val_loss improved from -0.62616 to -0.63029, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 6/50\n",
      "603/603 [==============================] - 194s 321ms/step - loss: -0.6320 - val_loss: -0.6278\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/50\n",
      "603/603 [==============================] - 173s 286ms/step - loss: -0.6398 - val_loss: -0.6324\n",
      "\n",
      "Epoch 00007: val_loss improved from -0.63029 to -0.63240, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 8/50\n",
      "603/603 [==============================] - 174s 288ms/step - loss: -0.6405 - val_loss: -0.6334\n",
      "\n",
      "Epoch 00008: val_loss improved from -0.63240 to -0.63338, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 9/50\n",
      "603/603 [==============================] - 182s 302ms/step - loss: -0.6434 - val_loss: -0.6352\n",
      "\n",
      "Epoch 00009: val_loss improved from -0.63338 to -0.63518, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 10/50\n",
      "603/603 [==============================] - 179s 297ms/step - loss: -0.6466 - val_loss: -0.6337\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/50\n",
      "603/603 [==============================] - 178s 295ms/step - loss: -0.6490 - val_loss: -0.6354\n",
      "\n",
      "Epoch 00011: val_loss improved from -0.63518 to -0.63538, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 12/50\n",
      "224/603 [==========>...................] - ETA: 1:59 - loss: -0.6509"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4aa3fdd4d8c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcheckpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model-dsbowl2018-1.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=50, \n\u001b[0;32m----> 5\u001b[0;31m                     callbacks=[earlystopper, checkpointer])\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/nuclei-detection/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda/envs/nuclei-detection/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nuclei-detection/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nuclei-detection/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nuclei-detection/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nuclei-detection/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda/envs/nuclei-detection/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nuclei-detection/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)\n",
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=50, \n",
    "                    callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1f381f5b-1b71-4daa-a417-e02f4894540b",
    "_uuid": "bb15226ea617cf91ed8f43179fccb5a15809e5a0"
   },
   "source": [
    "All right, looks good! Loss seems to be a bit erratic, though. I'll leave it to you to improve the model architecture and parameters! \n",
    "\n",
    "# Make predictions\n",
    "\n",
    "Let's make predictions both on the test set, the val set and the train set (as a sanity check). Remember to load the best saved model if you've used early stopping and checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2daa48d5-ac98-4e18-af3f-a582baaa44f0",
    "_uuid": "f841760b4abca1a25cb750822f88268bd79bf2ce"
   },
   "outputs": [],
   "source": [
    "# Predict on train, val and test\n",
    "model = load_model('model-dsbowl2018-1.h5', custom_objects={'mean_iou': mean_iou})\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "649248cd-a1fb-4da6-ade2-4bebad44bcab",
    "_uuid": "7e06242a50870e07a080064a4912b761775990fa"
   },
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random training samples\n",
    "ix = random.randint(0, len(preds_train_t))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_train_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "af602aea-5e56-42a8-9331-54b4b2650593",
    "_uuid": "5fcee2b9aee2fba5c60d43ad48a14139e9c1318c"
   },
   "source": [
    "The model is at least able to fit to the training data! Certainly a lot of room for improvement even here, but a decent start. How about the validation data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4f66b75c-c694-41a1-8c91-34bb6595837b",
    "_uuid": "d4ccbb559375bc2777ffb692a20adc313159f2cc"
   },
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random validation samples\n",
    "ix = random.randint(0, len(preds_val_t))\n",
    "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_val_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a6690535-b2e4-49ac-98d9-7191bfabfb6f",
    "_uuid": "6a34c98de7c6ae473f676a34fe7e099b46764eca"
   },
   "source": [
    "Not too shabby! Definitely needs some more training and tweaking.\n",
    "\n",
    "# Encode and submit our results\n",
    "\n",
    "Now it's time to submit our results. I've stolen [this](https://www.kaggle.com/rakhlin/fast-run-length-encoding-python) excellent implementation of run-length encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "59a0af60-a7d7-41ef-a6fe-9e3c72defa07",
    "_uuid": "4f99c1bf852e82b60bd4f982ca0df293f712cdf0"
   },
   "outputs": [],
   "source": [
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cutoff=0.5):\n",
    "    lab_img = label(x > cutoff)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "31133f8c-3f40-4dff-8e1d-898d56672332",
    "_uuid": "2e07f6afc4787b068ba714428145dcb3951d718f"
   },
   "source": [
    "Let's iterate over the test IDs and generate run-length encodings for each seperate mask identified by skimage ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "22fe24a1-7659-4cc9-9d23-211f38e5b99f",
    "_uuid": "089587843ed6a3955fdcb9b23a6ec3bf5d703688"
   },
   "outputs": [],
   "source": [
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_] * len(rle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "20b6b627-0fd6-425d-888f-da7f39efb124",
    "_uuid": "849184a40a2c9c21506d8b8eb10ad9155fa229e8"
   },
   "source": [
    "... and then finally create our submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1ba0ee3a-cca0-4349-83f6-09a1ac6fcb44",
    "_uuid": "ba589f56f5be1e6886bc88f5bf9e7d0a408e4048"
   },
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = new_test_ids\n",
    "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "sub.to_csv('sub-dsbowl2018-1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "222475b9-3171-461a-90f0-a820a6bd2634",
    "_uuid": "fb5e6f8cca872f1bd7036f6d9ac2ed2cab615536",
    "collapsed": true
   },
   "source": [
    "This scored 0.233 on the LB for me. That was with version 2 of this notebook; be aware that the results from the neural network are extremely erratic and vary greatly from run to run (version 3 is significantly worse, for example). Version 7 scores 0.277!\n",
    "\n",
    "You should easily be able to stabilize and improve the results just by changing a few parameters, tweaking the architecture a little bit and training longer with early stopping.\n",
    "\n",
    "**Have fun!**\n",
    "\n",
    "LB score history:\n",
    "- Version 7: 0.277 LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3f5e5a47-6133-4870-976a-a8e4fa7bf46c",
    "_uuid": "2a83eab66bf55194f300953bea5534b6a043130f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
